{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Métodos espectrais de alta ordem na resolução de equações diferenciais\n",
    "<center> <img src=\"./Figuras/ime.png\"  width=\"200\"> </center>\n",
    "Orientador:\n",
    "## Prof. Dr. Nelson Mukgayar Kuhl [IME - USP]\n",
    "\n",
    "Coorientador:\n",
    "## Dr. Paulo José Saiz Jabardo [CTMETRO - IPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# História\n",
    "O método espectral surgiu como uma ferramenta de alto poder computacional em mecânica de fluídos, proposto em 1944 por Blinova, implementado em 1954 por Silberman, praticamente abandonado no meio da década de 60 e ressurgindo em 1969-1970 por Orszag, Eliason e Manchenhauer  e Rasmussen, foi desenvolvido para aplicações especializadas. No entanto,  somente em 1977 foi formalizado matematicamente por Gottlieb e Orszag.\n",
    "\n",
    "Originalmente o método espectral foi promovido por meteorologistas no estudo de modelos globais de tempo e especialistas em dinâmica de fluídos estudando turbulência isotrópica. Desde a década de 80 até hoje o  estudo na área de CFD (Computational Fluid Dynamics- dinâmica dos fluidos computacional), para solucionar problemas de equações diferenciais do tipo de Sturm-Liouville, tem crescido lado a lado ao avanço computacional que o tornou possível.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A monografia\n",
    " Neste trabalho, irei realizar algumas das técnicas do método espectral para a resolução de equações diferenciais em 1D (uma dimensão) apresentados por G. Karniadakis e S. Sherwin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linguagem Julia\n",
    "\n",
    "<center> <img src=\"./Figuras/julia.png\"  width=\"100\"> </center>\n",
    "\n",
    "* Aspectos positivos :\n",
    "     * características de linguagem de alto nível:\n",
    "         * polimorfismo\n",
    "         * tipagem dinâmica\n",
    "         * fácil implementação\n",
    "     * desempenho comparável a linguagens de baixo nível como (C e fortran)\n",
    "     * comunidade científica em crescimento\n",
    "     * utiliza algumas bibliotecas já conhecidas da linguagem python \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linguagem Julia\n",
    "\n",
    "<center> <img src=\"./Figuras/julia.png\"  width=\"100\"> </center>\n",
    "\n",
    "* Aspectos negativos :\n",
    "    * linguagem muito nova (Ver. 0.5)\n",
    "        * constante mudança de funções da biblioteca base \n",
    "        * falta de algumas bibliotecas expecíficas (que estão sendo implementadas)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tópicos\n",
    "\n",
    "1. Métodos espectral (interpolação, diferenciação, integração)\n",
    "2. Fenômeno Runge\n",
    "3. método dos resíduos ponderados\n",
    "4. elementos finitos\n",
    "5. resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método espectral\n",
    "Diferentemente do método das diferenças finitas, que considera apenas os pontos próximos do ponto\n",
    "que queremos computar chamada de método local, o método espectral considera todo o domínio,\n",
    "sendo assim um método global.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método espectral\n",
    "\\begin{align}\n",
    " P_n(x_i) &= f(x_i)\\\\\n",
    " P_n(x) &\\equiv \\sum_{i = 0}^{N} f(x_i)C_i(x) \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método espectral\n",
    "\n",
    "onde $C_i$ pode ser um polinômio base de Lagrange ou qualquer outro polinômio interpolador.\n",
    "\\begin{equation}\n",
    "C_i(x) = \\prod_{j = 0 \\\\ j \\neq i}^{N} \\frac{x - x_j}{x_i - x_j} \n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método espectral\n",
    "\n",
    "Exemplo para um polinômio de lagrange para 6 pontos:\n",
    "<img src= \"./Figuras/exemplo_polinomio_lagrange.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Porém, essa interpolação nem sempre dá certo. -Carl Runge\n",
    "\n",
    "<img src= \"./Figuras/fenomeno_runge.png\" width=850 >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fenômeno de Runge\n",
    "Para minimizar esses erros, temos que achar raízes de polinômios que minimizem o erro de interpolação da função:\n",
    "## Teorema de cauchy:\n",
    "\\begin{equation}\n",
    " f(x) - P_{N+1}(x) = \\frac{1}{[N+1]!}f^{(N+1)}(\\epsilon){\\color{Red}{ \\prod^{N}_{i = 0} (x - x_i)}} \\\\\n",
    "  \\epsilon(x) \\in [-1,1].\n",
    "  \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fenômeno de Runge\n",
    "\n",
    "Utilizando as raízes do polinômio $T_i$ de Chebyshev, conseguimos minimizar esse erro:\n",
    "\\begin{align}\n",
    "    &T_0(x) = 1\\\\\n",
    "    &T_1(x) = x\\\\\n",
    "    &T_{N+1}(x) = 2xT_N(x) - T_{N-1}(x)\\\\\n",
    "    &T_{N}(x) =\\cos(n \\arccos x)=\\cosh(n\\,\\operatorname{arcosh}\\,x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fenômeno de Runge\n",
    "<img src=\"./Figuras/chebychev_equidist.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método Espectral\n",
    "## Integração\n",
    "\\begin{align}\n",
    "\\int^{a}_b f(x) \\partial x\\ \\approx \\int^{a}_b P_n(x)\\ \\partial x\\ &=\\ \\sum_{i\\ =\\ 0}^N f(x_i) \\int^{a}_b C_i(x) \\partial x\\\\ &=\\ \\color{Green}{ \\sum_{i\\ =\\ 0}^N f(x_i) w_i \\\\}\n",
    "\\end{align} \n",
    "onde :\n",
    "\\begin{equation}\n",
    " w_i =  \\int^{a}_b  C_i(x) \\partial x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método Espectral\n",
    "## Derivação\n",
    "\\begin{equation}\n",
    "   \\frac{\\partial f(x)}{\\partial x}  \\Biggm\\lvert_{x=x_i} =\\color{Green}{ \\sum^{N}_{j\\ = 0} f(x_j) C_{ij}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    " Onde:\n",
    " \\begin{equation}\n",
    "  C_{ij} = \\frac{\\partial C_j(x)}{\\partial x} \\Biggm\\lvert_{x=x_i}\n",
    " \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método Espectral\n",
    "## Polinômio de Jacobi\n",
    " Polinômios de Jacobi $P^{\\alpha,\\beta}_n(x)$ são famílias de polinômios de soluções para problemas de *Sturm-Liouville*. Tais polinômios são ***ortogonais*** no intervalo $[-1,1]$  com respeito funções peso do tipo $(1-x)^\\alpha (1+x)^\\beta$ para $\\alpha,\\beta > -1$.\n",
    "Pela fórmula de Rodrigues, essa família é dada por:\n",
    "\\begin{equation}\n",
    "P_n^{(\\alpha,\\beta)}(x) = \\frac{(-1)^n}{2^n n!} (1-x)^{-\\alpha} (1+x)^{-\\beta} \\frac{d^n}{dx^n} \\left\\{ (1-x)^\\alpha (1+x)^\\beta \\left (1 - x^2 \\right )^n \\right\\},\\ (\\alpha, \\beta >-1)\n",
    "\\end{equation}\n",
    " sua derivada é dada por:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial P^{\\alpha,\\beta}_n (x)}{\\partial x} = \\frac{1}{2}(n+\\alpha+\\beta) P^{\\alpha + 1,\\beta +1}_{n-1} (x)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método Espectral\n",
    "## Polinômio de Jacobi\n",
    "onde podemos encontrar $P^{\\alpha + 1,\\beta +1}_{n-1}$ pela relação recursiva:\n",
    "\\begin{align}\n",
    "& P^{\\alpha,\\beta}_{0} (x) = 1\\\\\n",
    "& P^{\\alpha,\\beta}_{1} (x) = \\frac{1}{2}[\\alpha - \\beta + (\\alpha + \\beta + 2 )x]\\\\\n",
    "& P^{\\alpha,\\beta}_{n+1} (x)=(a^2_n + a ^3_n x)P^{\\alpha,\\beta}_{n}(x) - a_n^4P^{\\alpha,\\beta}_{n-1}(x)  \\\\\n",
    "& a^1_n = 2(n+1)(n+ \\alpha + \\beta + 1)(2n + \\alpha +\\beta)\\\\\n",
    "& a^2_n = (2n + \\alpha +\\beta + 1)(\\alpha^2 - \\beta^2)\\\\\n",
    "& a^3_n = (2n + \\alpha +\\beta)(2n + \\alpha +\\beta + 1)(2n + \\alpha + \\beta + 2)\\\\ \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos resíduos ponderados\n",
    "\n",
    "Dado $u(x)$ a solução da equação diferencial:\n",
    " \\begin{align}\n",
    "     L(u) &= \\frac{\\partial^2 u}{\\partial x^2} + \\lambda u + f = 0 \\\\\n",
    "    L(u) &= 0\n",
    " \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos resíduos ponderados\n",
    " Aproximando $u$ por $u^\\delta$ obtemos um erro $R(u^\\delta)$ associado ao operador $L(\\bullet)$:\n",
    " \\begin{align}\n",
    " \tu^\\delta(x) &= u(x_0) + \\sum^{N_{dof}}_{i = 1} u(x_i) \\Phi(x)\\\\\n",
    "    L(u^\\delta) &= R(u^\\delta)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos resíduos ponderados\n",
    "\n",
    "Nosso problema está na minimização desse erro $R(u^\\delta)$. Para isso, escolhemos uma função teste $v_j$ onde $j = 1,2,\\dots, N_{dof}$, tal que seu produto interno com o erro seja o menor possível.\n",
    "\\begin{equation}\n",
    "    <v_j,R(u^\\delta)> = \\int_{\\Omega} v_j(x)\\ R(x) \\partial x,\\ \\forall j = 1,2,3,\\dots,N_{dof}\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos resíduos ponderados\n",
    "\n",
    "Assim, obtemos um sistema linear para cada j no qual escolhido a melhor função teste $v_j$, temos a melhor aproximação $u^\\delta$. Ao longo dos anos várias funções foram encontradas para a minimização dos erros. O método mais conhecido é o dos Mínimos Quadrados no qual $v_j\\ =\\ \\frac{\\partial R}{\\partial \\hat{u}_j}$. Alguns outros também existem como o método de *colocação* e método dos *momentos*. Aquele que usarei é o método de **Galerkin**, onde escolhemos $v_j \\equiv \\phi_j$ e $v_j(\\Omega_d) = 0$ onde $\\Omega_d$ é a fronteira de *Dirichlet*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método de Galerkin\n",
    " O método de ***Galerkin***, também conhecido como \\emph{Bubnov-Galerkin} devido a Ivan Grigoryevich Bubnov  e Boris Grigoryevich Galerkin  será o mais utilizado daqui pra frente. Para fins de exemplo consideramos a seguinte equação diferencial em uma dimensão:\n",
    " \\begin{equation} \n",
    " L(u) \\equiv \\frac{\\partial^2 u}{\\partial x^2} + f = 0\n",
    " \\end{equation}\n",
    " \n",
    " Para esse problema ser bem posto e então obter uma solução única, precisamos especificar as condições de fronteira num domínio $\\Omega = \\{x| -1 < x < 1\\}$, assim sendo temos:\n",
    " \\begin{equation}\n",
    " u(-1)=g_D\\ ,\\ \\frac{\\partial u(1)}{\\partial x} = g_N\n",
    " \\end{equation}\n",
    " Onde $g_D$ e $g_N$, são constantes, e são chamadas de condição de contorno de *D*irichlet e *N*eumman. Essas condições junto da equação , chamamos essa combinação como formulação *Forte* do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formulação fraca\n",
    "\n",
    " Como a função teste $v$ é zero na fronteira de *Dirichlet*, sabemos que $v(-1) = 0$. Assim, aplicando a condição de fronteira de *Neumman*, $\\frac{\\partial u(1)}{\\partial x} = g_N$, simplificamos a equação, temos:\n",
    "\\begin{equation}\n",
    " (v,L(u))=\\int^1_{-1} v\\left ( \\frac{\\partial^2u}{\\partial x^2} + f \\right )\\partial x = 0\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formulação fraca\n",
    "\n",
    "Podemos ver que essa equação pode ser reescrita usando integração por partes obtemos:\n",
    "\n",
    " \\begin{align}\n",
    "& \\int^{1}_{-1} v \\frac{\\partial^2 u}{\\partial x^2} \\partial x = \\left [ v\\frac{\\partial u}{\\partial x}    \\right ]^{1}_{-1} - \\int^{1}_{-1} \\frac{\\partial v}{\\partial x}  \\frac{\\partial u}{\\partial x}  \\partial x \\\\\n",
    "&  \\int^{1}_{-1} \\frac{\\partial v}{\\partial x}  \\frac{\\partial u}{\\partial x}  \\partial x =  \\int^{1}_{-1}  v f\\ \\partial x  + \\left [ v\\frac{\\partial u}{\\partial x}    \\right ]^{1}_{-1} \n",
    " \\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formulação fraca\n",
    "\n",
    "\\begin{equation}\n",
    " \\int^{1}_{-1} \\frac{\\partial v}{\\partial x}  \\frac{\\partial u}{\\partial x}  \\partial x =  v(1)g_N + \\int^{1}_{-1}  v f\\ \\partial x  \n",
    "\\end{equation}\n",
    "\n",
    "Vemos que nessa última etapa, a condição de fronteira de *Neumman* é naturalmente inclusa na formulação. A forma integral da equação como vimos nas últimas duas etapas, é dita como a ***Formulação Fraca*** do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementação da condição de fronteira de Dirichlet\n",
    "Como toda função teste $v^\\delta(x)$ é zero na fronteira de *Dirichlet*, fica claro que $u^\\delta$ deve conter outra função não zero na fronteira, sem isso não seria possível satisfazer a condição de fronteira de *Dirichlet* do problema. Então temos que a solução aproximada $u^\\delta$ é uma combinação de outras duas funções: $u^d$, que satisfaz as condições de fronteira de *Dirichlet* e uma função *h*omogênea desconhecida $u^h$, que é zero na fronteira de Dirichelt.\n",
    " \\begin{align}\n",
    " u^\\delta = \\color{Green} {u^d} + \\color{Red} {u^h} \\\\\n",
    " u^h(\\partial \\Omega_D) = 0,\\ u^d(\\partial \\Omega_D) = g_d\n",
    " \\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Implementação da condição de fronteira de Dirichlet\n",
    "Da equação dada pela formulação fraca temos:\n",
    "\n",
    "\\begin{equation}\n",
    " \\int^{1}_{-1} \\frac{\\partial v}{\\partial x}  \\frac{\\partial u}{\\partial x}  \\partial x =  v(1)g_N + \\int^{1}_{-1}  v f\\ \\partial x  \n",
    "\\end{equation}\n",
    "aplicando  $u^\\delta = \\color{Green} {u^d} + \\color{Red} {u^h} $:\n",
    "\n",
    " \\begin{align}\n",
    "  & \\int^{1}_{-1} \\frac{\\partial v^\\delta}{\\partial x}  \\frac{\\partial u^\\delta}{\\partial x}  \\partial x =  \\color{Red} {\\int^{1}_{-1} \\frac{\\partial v^\\delta}{\\partial x}  \\frac{\\partial u^h}{\\partial x}  \\partial x } + \\color{Green} { \\int^{1}_{-1} \\frac{\\partial v^\\delta}{\\partial x}  \\frac{\\partial u^d}{\\partial x}  \\partial x} \\\\\n",
    "& \\color{Red} {\\int^{1}_{-1} \\frac{\\partial v^\\delta}{\\partial x}  \\frac{\\partial u^h}{\\partial x}  \\partial x}= \\color{Green} { v^\\delta(1)g_N + \\int^{1}_{-1}  v^\\delta f\\ \\partial x -    \\int^{1}_{-1} \\frac{\\partial v^\\delta}{\\partial x}  \\frac{\\partial u^d}{\\partial x}  \\partial x }\n",
    " \\end{align}\n",
    " \n",
    " a equação  é dada por um sistema algébrico onde os termos do lado direito são conhecidos e a solução homogênea $u^h$ e $v^\\delta$ são funções discretizadas. Assim o método de *Galerkin* nos permite reduzir uma *equação diferencial* num problema algébrico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    " O método dos elementos finitos para equações diferenciais de segunda ordem, estima $v^\\delta$ por uma classe de funções $C^0$ contínua, onde essa aproximada é contínua em todo domínio $\\Omega$. A solução do método é dividir esse domínio em finitos elementos, da forma $\\Omega^e$, onde a derivada também é contínua. No entanto nas fronteiras entre os elementos, sua derivada pode ser descontínua apesar da função ser $C^0$ contínua.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\\begin{align} \n",
    " \\int^1_{-1} \\frac{\\partial v^\\delta}{\\partial x}\\frac{\\partial u^\\delta}{\\partial x} \\partial x&= \n",
    "\\sum^{N_{el}}_{e=1} \\int_{\\Omega^e}\\frac{\\partial v^\\delta}{\\partial x}\\frac{\\partial u^\\delta}{\\partial x} \\partial x\\\\\n",
    "& = - \\sum^{N_{el}}_{e=1} \\int_{\\Omega^e} v^\\delta\\frac{\\partial^2 u^\\delta}{\\partial x^2} \\partial x +\\sum^{N_{el}}_{e=1} \\left [ v^\\delta \\frac{\\partial u^\\delta}{\\partial x}\\right ]^{\\Omega^e_D}_{\\Omega^e_E}\\\\\n",
    "& = -\\int^1_{-1} v^\\delta\\frac{\\partial^2 u^\\delta}{\\partial x^2}  \\partial x +\\sum^{N_{el}}_{e=1} \\left [ v^\\delta \\frac{\\partial u^\\delta}{\\partial x}\\right ]^{\\Omega^e_D}_{\\Omega^e_E}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\n",
    "# Exemplo\n",
    "\n",
    " Considere a equação unidimensional de Poisson:\n",
    "\\begin{equation}\n",
    "L(u) \\equiv \\frac{\\partial^2 u}{\\partial x^2} + f = 0\n",
    "\\end{equation}\n",
    " Onde $f(x)$ é uma função conhecida e as condições de fronteira são:\n",
    "\\begin{equation}\n",
    "u(0) = g_d= 1,\\ \\ \\frac{\\partial u}{\\partial x}(1)= g_n = 1\n",
    "\\end{equation}\n",
    " Sabendo a formulação fraca, que é dada como:\n",
    "\\begin{equation}\n",
    "\\color{Blue}{\\int^1_0 \\frac{\\partial v^\\delta}{\\partial x} \\frac{\\partial u^\\delta}{\\partial x} \\partial x\\ } = \\color{Purple}{\\int^1_0v^\\delta f\\ \\partial x }+ \\color{Green}{v^\\delta(1)g_n }-\\color{Red}{ \\int^1_0 \\frac{\\partial v^\\delta}{\\partial x} \\frac{\\partial u^D}{\\partial x}\\ \\partial x}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\\begin{equation}\n",
    "u^\\delta = \\sum^2_{i=0} \\hat{u_i}\\phi_i(x) \n",
    "\\end{equation} \n",
    "<img src=\"./Figuras/screenshot_elementosfinitos.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "separação entre a solução *homogênea* e *dirichlet*:\n",
    "\\begin{align}\n",
    " & u^H = \\hat{u_1}\\phi_1(x) + \\hat{u_2}\\phi_2(x)\n",
    " & u^D = g_D\\phi_0(x)\n",
    " \\end{align}\n",
    " \n",
    "  onde $\\hat{u_0}\\ e \\hat{u_1}$ são arbitrários. A aproximação definida em $u^H$ contém as mesmas funções usadas na função teste $v$, tendo :\n",
    " \\begin{equation}\n",
    " v^\\delta(x) = \\hat{v_1}\\phi_1(x) + \\hat{v_2}\\phi_2(x)\n",
    " \\end{equation}\n",
    " tanto $\\hat{v_0}$ e $\\hat{v_1}$ são *desconhecidos*. Definimos $f(x)$ como uma expansão idêntica de $u^\\delta$ em relação a $\\phi$:\n",
    " \\begin{equation}\n",
    " f(x) = \\sum^2_{i=0} \\hat{f_0}\\phi_0(x) +\\hat{f_1}\\phi_1(x) + \\hat{f_2}\\phi_2(x)\n",
    " \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Caso $f$ seja constante ou linear, então a aproximação é exata. Para funções algo mais complexo, os coeficientes $\\hat{f_0},\\hat{f_1},\\hat{f_2}$, tem que ser determinada e podem ser escolhidas como  $\\hat{f_0} = f(0),\\hat{f_1} = f(0.5),\\hat{f_2} = f(1)$.\n",
    "\n",
    " Definidos $u$,$v$,$f$ podemos calcular cada termo na equação:\n",
    " primeiro termo:\n",
    "\\begin{align}\n",
    "\\color{Blue}{\\int^1_0 \\frac{\\partial v^\\delta}{\\partial x} \\frac{\\partial u^\\delta}{\\partial x} \\partial x\\ }& = \\color{Blue}{\\int^{\\frac{1}{2}}_0 (2\\hat{v_1})(2\\hat{u_1}) \\partial x + \\int^1_{\\frac{1}{2}} (-2\\hat{v_1}+2\\hat{v_2})(-2\\hat{u_1}+2\\hat{u_2}) \\partial x }\n",
    "\\\\\n",
    "& = \\color{Blue}{[\\hat{v_1}\\ \\ \\hat{v_2} ]\\begin{bmatrix}\n",
    "4 & -2 \\\\ \n",
    "-2 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\hat{u_1}\\ \\\\ \\hat{u_2}\\\\ \n",
    "\\end{bmatrix}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\n",
    "segundo termo:\n",
    "\\begin{align}\n",
    "\\color{Purple}{\\int^1_0v^\\delta f\\ \\partial x }= &\\color{Purple}{ \\int^{\\frac{1}{2}}_0 (2\\hat{v_1}x)(\\hat{f_0}(1-2x) + \\hat{f_1}(2x) \\partial x} + \\\\\n",
    "&\\color{Purple}{ \\int^1_{\\frac{1}{2}} (\\hat{v_1}2(1-x) +\\hat{v_2}(2x-1))(\\hat{f_1}2(1-x) +\\hat{f_2}(2x-1)) \\partial x}\\\\\n",
    "& \\color{Purple}{[\\hat{v_1}\\ \\hat{v_2}]\\begin{bmatrix}\n",
    "\\frac{1}{12}\\hat{f_0} + \\frac{1}{3}\\hat{f_1} + \\frac{1}{12}\\hat{f_2} \\\\ \n",
    "\\frac{1}{12}\\hat{f_0} + \\frac{1}{6}\\hat{f_2}\n",
    "\\end{bmatrix}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "terceiro termo:\n",
    "\\begin{equation}\n",
    "\\color{Green}{v^\\delta(1)g_n = (\\hat{v_1}\\phi_1(1) + \\hat{v_2}\\phi_2(1))g_N = [\\hat{v_1} \\ \\hat{v_2}]\\begin{bmatrix}\n",
    "0\\\\ \n",
    "1\n",
    "\\end{bmatrix}g_n}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\n",
    "quarto termo:\n",
    " \\begin{align}\n",
    " \\color{Red}{ \\int^1_0 \\frac{\\partial v^\\delta}{\\partial x}\\frac{\\partial u^\\delta}{\\partial x}} &= \\color{Red}{\\int^{\\frac{1}{2}}_0 (2\\hat{v_1})(-2g_D)\\ \\partial x }\\\\\n",
    "             &= \\color{Red}{ [\\hat{v_1}\\ \\hat{v_2}]\\begin{bmatrix}\n",
    "-2g_D\\\\ \n",
    "0\n",
    "\\end{bmatrix}}\n",
    " \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método dos elementos finitos\n",
    "\n",
    "Resolvendo esse sistema linear na forma matricial, encontramos a função $u(\\bullet)$:\n",
    "\\begin{equation}\n",
    "u^\\delta =\n",
    "\\begin{cases}\n",
    "1 + x +\\frac{x}{12}\\hat{f_0} + \\frac{5x}{12}\\hat{f_1} +\\frac{x} {4}\\hat{f_2},\\ \\ 0 \\leq x \\leq \\frac{1}{2}\\\\\n",
    "1 + x +\\frac{1}{24}\\hat{f_0} + \\frac{2+x}{12}\\hat{f_1} +\\frac{1+4x}{24}\\hat{f_2},\\ \\ \\frac{1}{2} \\leq x \\leq 1\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assim substituindo cada termo e botando $[\\hat{v_1}\\ \\hat{v_2}]$ em evidência, temos:\n",
    "\\begin{align}\n",
    "[\\hat{v_1}\\ \\hat{v_2}]\\begin{Bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 & -2 \\\\ \n",
    "-2 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\hat{u_1}\\ \\\\ \\hat{u_2}\\\\ \n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{12}\\hat{f_0} + \\frac{1}{3}\\hat{f_1} + \\frac{1}{12}\\hat{f_2} \\\\ \n",
    "\\frac{1}{12}\\hat{f_0} + \\frac{1}{6}\\hat{f_2}\n",
    "\\end{bmatrix}-\n",
    "\\begin{bmatrix}\n",
    "0\\\\ \n",
    "g_n\n",
    "\\end{bmatrix}+\n",
    "\\begin{bmatrix}\n",
    "-2g_D\\\\ \n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\end{Bmatrix}\n",
    "=0\n",
    "\\end{align}\n",
    " Assim, notamos que para quaisquer $[\\hat{v_1},\\ \\hat{v_2}]$,podemos solucionar essa equação, apenas resolvendo a equação dentro dos **colchetes**,fazendo $g_D$ e $g_N$ ambos iguais a $1$, temos:\n",
    "\\begin{equation}\n",
    " \\begin{bmatrix}\n",
    "\\hat{u_1}\\ \\\\ \\hat{u_2}\\\\ \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\\frac{3}{2} +\\frac{1}{24}\\hat{f_0}+\\frac{5}{24}\\hat{f_1}+\\frac{1}{8}\\hat{f_2} \\\\ 2 +\\frac{1}{24}\\hat{f_0}+\\frac{1}{4}\\hat{f_1}+\\frac{5}{24}\\hat{f_2} \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma Matricial do problema\n",
    "Ao decidir resolver a equação diferencial, obtemos um sistema de equações diferenciais para cada função teste $v_j^\\delta$  e sem perder a igualdade transformamos o problema diferencial em um problema variacional, segue o exemplo abaixo :\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial^2 u^\\delta }{\\partial x^2} + \\lambda u^\\delta &= f\\\\[1.5pt]\n",
    "v^\\delta_j (\\frac{\\partial^2 u^\\delta }{\\partial x^2} + \\lambda v^\\delta_j\\ u^\\delta) \\ &= v^\\delta_j f\\\\[1.5pt]\n",
    "\\int_\\Omega v^\\delta_j (\\frac{\\partial^2 u^\\delta }{\\partial x^2} + \\lambda v^\\delta_j\\  u^\\delta) \\partial x &= \\int_\\Omega v^\\delta_j  f \\partial x\\\\[1.5pt]\n",
    "\\int_\\Omega v^\\delta_j \\frac{\\partial^2 u^\\delta }{\\partial x^2}\\ \\partial x + \\int_\\Omega \\lambda v^\\delta_j\\ u^\\delta\\partial x &=\\ \\int_\\Omega v^\\delta_j  f \\partial x\\\\[1.5pt]\n",
    "\\int_\\Omega \\frac{\\partial v^\\delta_j }{\\partial x} \\frac{\\partial u^\\delta }{\\partial x}\\ \\partial x + \\int_\\Omega \\lambda v^\\delta_j\\ u^\\delta\\ \\partial x - (v^\\delta_j  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega\\ &=\\  \\int_\\Omega v^\\delta_j\\  f\\ \\partial x \\ \\forall j = 1,2,3,\\dots,N \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma Matricial do problema\n",
    "\n",
    "Como $u^\\delta$ é a aproximada de $u$ utilizando a função teste $v^\\delta_j$, temos:\n",
    "\\begin{align}\n",
    "u_i&=u(x_i)\\\\\n",
    "u^\\delta(x) &= \\sum^N_{i=0} v_i(x)u_i\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "\\sum^N_{i=1} u_i \\int_\\Omega \\frac{\\partial v^\\delta_j }{\\partial x} \\frac{\\partial v^\\delta_i }{\\partial x}\\ \\partial x +\\sum^N_{i=1} u_i  \\int_\\Omega \\lambda\\ v^\\delta_j v^\\delta_i \\ \\partial x =\\  (v^\\delta_j  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega + \\int_\\Omega v^\\delta_j\\ f\\ \\partial x \\ \\forall j =1,2,\\dots,N \n",
    "\\end{align}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma Matricial do problema\n",
    "\n",
    "\\begin{align}\n",
    "\\sum^N_{i=1} u_i \\left \\{  \\int_\\Omega \\frac{\\partial v^\\delta_j }{\\partial x} \\frac{\\partial v^\\delta_i }{\\partial x}\\ \\partial x + \\int_\\Omega \\lambda\\ v^\\delta_j v^\\delta_i \\ \\partial x \\right \\} =\\  (v^\\delta_j  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega + \\int_\\Omega v^\\delta_j\\ f\\ \\partial x \\ \\forall j =1,2,\\dots,N \n",
    "\\end{align}  \n",
    "Que pode ser escrita matricialmente como :\n",
    "\\begin{equation}\n",
    "\\{ M + \\lambda S\\} U = F\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma Matricial do problema\n",
    "\n",
    "\n",
    " Onde chamamos a matriz M de matriz de massa e S de matriz de rigidez.\n",
    "\\begin{align}\n",
    "M &=\n",
    "\\begin{bmatrix}\n",
    "\\int_\\Omega \\frac{\\partial v^\\delta_{1}}{\\partial x}\\frac{\\partial v^\\delta_{1}}{\\partial x}\\ \\partial x  & \\int_\\Omega \\frac{\\partial v^\\delta_{1}}{\\partial x}\\frac{\\partial v^\\delta_{2}}{\\partial x}\\ \\partial x  & \\dots & \\int_\\Omega \\frac{\\partial v^\\delta_{1}}{\\partial x}\\frac{\\partial v^\\delta_{N}}{\\partial x}\\ \\partial x  \\\\ \n",
    "\\int_\\Omega \\frac{\\partial v^\\delta_{1}}{\\partial x}\\frac{\\partial v^\\delta_{2}}{\\partial x}\\ \\partial x  & \\int_\\Omega \\frac{\\partial v^\\delta_{2}}{\\partial x}\\frac{\\partial v^\\delta_{2}}{\\partial x}\\ \\partial x  & \\dots & \\int_\\Omega \\frac{\\partial v^\\delta_{2}}{\\partial x}\\frac{\\partial v^\\delta_{N}}{\\partial x}\\ \\partial x  \\\\ \n",
    "\\vdots & \\vdots & \\vdots & \\dots \\\\\n",
    "\\int_\\Omega \\frac{\\partial v^\\delta_{N}}{\\partial x}\\frac{\\partial v^\\delta_{1}}{\\partial x}\\ \\partial x  & \\int_\\Omega \\frac{\\partial v^\\delta_{N}}{\\partial x}\\frac{\\partial v^\\delta_{2}}{\\partial x}\\ \\partial x  & \\dots & \\int_\\Omega \\frac{\\partial v^\\delta_{N}}{\\partial x}\\frac{\\partial v^\\delta_{N}}{\\partial x}\\ \\partial x  \\\\ \n",
    "\\end{bmatrix}, \\\\\n",
    "S &= \\begin{bmatrix}\n",
    "\\int_\\Omega v^\\delta_1 v^\\delta_1 \\partial x & \\int_\\Omega v^\\delta_1 v^\\delta_2 \\partial x & \\dots & \\int_\\Omega v^\\delta_1 v^\\delta_N \\partial x \\\\ \n",
    "\\int_\\Omega v^\\delta_2 v^\\delta_1 \\partial x & \\int_\\Omega v^\\delta_2 v^\\delta_2 \\partial x & \\dots & \\int_\\Omega v^\\delta_2 v^\\delta_N \\partial x\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\int_\\Omega v^\\delta_N v^\\delta_1 \\partial x & \\int_\\Omega v^\\delta_N v^\\delta_2 \\partial x & \\dots & \\int_\\Omega v^\\delta_N v^\\delta_3 \\partial x\n",
    "\\end{bmatrix},\\\n",
    "U = \\begin{bmatrix}\n",
    "u_1\\\\ \n",
    "u_2\\\\ \n",
    "\\vdots \\\\\n",
    "u_N\n",
    "\\end{bmatrix}\\\\\n",
    "\\end{align}\n",
    "onde M é a matriz de massa e S é a matriz de rigidez (stifness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma Matricial do problema\n",
    "\n",
    "\\begin{align}\n",
    "F &= \\begin{bmatrix}\n",
    "\\int_\\Omega v^\\delta_1\\ f\\ \\partial x +  (v^\\delta_1  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega \\\\ \n",
    "\\int_\\Omega v^\\delta_2\\ f\\ \\partial x +  (v^\\delta_2  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega \\\\ \n",
    "\\vdots \\\\\n",
    "\\int_\\Omega v^\\delta_N\\ f\\ \\partial x +  (v^\\delta_N  \\frac{\\partial u^\\delta }{\\partial x})\\Biggm\\lvert_\\Omega\\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "\n",
    "Quando tratamos das funções de bases, temos as funções globais e as locais. Apesar das funções globais serem na teoria usadas para o calcular as matrizes de *massa* e de *rigidez*, na prática decompomos as funções globais em elementos e utilizamos dessa decomposição as funções de base locais para o cálculo das matrizes.\n",
    "\n",
    " Tomemos como exemplo as funções lineares globais $\\Phi$ em um domínio $\\Omega = \\{x\\ |\\ 0\\leq x \\leq 1\\}$ subdividido em \\emph{3} elementos. Temos 4 graus de liberdade nessa expansão, definida no máximo em 2 elementos ao mesmo tempo,que vale 1 em um dos extremos desses elementos e decresce para 0 para o em direção aos outros extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "\\begin{equation}\n",
    "\\Phi_1(x) = \\left\\{\\begin{matrix}\n",
    "1 - 3x,\\ 0 \\leq x \\leq \\frac{1}{3}\\\\\n",
    "0\\ , \\frac{1}{3} < x \\leq 1\n",
    "\\end{matrix}\\right.\\ \\ \n",
    "\\Phi_2(x) = \\left\\{\\begin{matrix}\n",
    "3x,\\ 0 \\leq x \\leq \\frac{1}{3}\\\\\n",
    "2 - 3x\\ , \\frac{1}{3} < x \\leq \\frac{2}{3}\\\\\n",
    "0\\ , \\frac{2}{3} < x \\leq 1\n",
    "\\end{matrix}\\right.\\\\\n",
    "\\end{equation} \n",
    "\\begin{equation}\n",
    "\\Phi_3(x) = \\left\\{\\begin{matrix}\n",
    "0 ,\\ 0 \\leq x < \\frac{1}{3}\\\\\n",
    "3x - 1\\ ,\\ \\frac{1}{3} < x \\leq \\frac{2}{3}\\\\\n",
    "-3x + 3 \\ ,\\ \\frac{2}{3} < x \\leq 1\n",
    "\\end{matrix}\\right.\\\\\n",
    "\\Phi_4(x) = \\left\\{\\begin{matrix}\n",
    "0\\ ,\\ \\ 0 \\leq x < \\frac{1}{3}\\\\\n",
    "0\\ ,\\ \\frac{1}{3} < x \\leq \\frac{2}{3}\\\\\n",
    "3x -2 \\ ,\\ \\frac{2}{3} < x \\leq 1\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "<img src=\"./Figuras/Matrix_elem_global.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "Também podemos definir funções locais $\\phi^e_p(x)$ onde $\\Omega_e = \\{x \\| x_{e1} \\leq x \\leq x_{e2} \\}$:\n",
    "\\begin{equation}\n",
    "\\phi^e_1\\ = \\left\\{\\begin{matrix}\n",
    "\\frac{x_{e1}\\ -\\ x}{x_{e2} - x_{e1}}, x \\in \\Omega_e \\\\\n",
    "0 ,\\ x \\notin \\Omega_e \n",
    "\\end{matrix}\\right.\n",
    "\\phi^e_2\\ = \\left\\{\\begin{matrix}\n",
    "\\frac{x\\ -\\ x_{e1}}{x_{e2} - x_{e1}}, x \\in \\Omega_e \\\\\n",
    "0 ,\\ x \\notin \\Omega_e \n",
    "\\end{matrix}\\right.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "\n",
    "<img src=\"./Figuras/Matrix_element_local.png\">\n",
    "\\begin{align}\n",
    "\\Phi_1 &= \\phi_{1}^{1} \\\\[0.5pt]\n",
    "\\Phi_2 &= \\phi_{2}^{1} + \\phi_{1}^{2} \\\\[0.5pt]\n",
    "\\Phi_3 &= \\phi_{2}^{2} + \\phi_{1}^{3} \\\\[0.5pt]\n",
    "\\Phi_4 &= \\phi_{2}^{3}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "\\phi_1^1\\\\[1.9pt] \n",
    "\\phi_2^1\\\\[1.9pt]\n",
    "\\phi_1^2\\\\[1.9pt] \n",
    "\\phi_2^2\\\\[1.9pt]\n",
    "\\phi_1^3\\\\[1.9pt] \n",
    "\\phi_2^3\\\\[1.9pt] \n",
    "\\end{bmatrix}\\ = \\\n",
    "\\begin{bmatrix}\n",
    "1 &0  & 0 & 0 \\\\ \n",
    "0 & 1 & 0 & 0\\\\ \n",
    "0 & 1 & 0 & 0\\\\ \n",
    "0 &0  & 1 & 0\\\\ \n",
    "0 &0  & 1 & 0\\\\ \n",
    "0 &0  & 0 & 1\n",
    "\\end{bmatrix}\\\n",
    "\\begin{bmatrix}\n",
    "\\Phi_1\\\\ \n",
    "\\Phi_2\\\\ \n",
    "\\Phi_3\\\\ \n",
    "\\Phi_4\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento \n",
    "\n",
    "Devido ao fato da matriz $A$ ser uma matriz esparsa e portanto numericamente ineficiente para ser usada como um operador, utilizamos outra saída. Essa alternativa é uma matriz \\emph{map}eadora em que cada coluna é um elemento (e) e cada linha o indice da função global (i).\n",
    "\\begin{equation}\n",
    "map[1,i]= \\begin{bmatrix}\n",
    "1\\\\\n",
    "2\n",
    "\\end{bmatrix},\\\n",
    "map[2,i]= \\begin{bmatrix}\n",
    "2\\\\\n",
    "3\n",
    "\\end{bmatrix}\\\n",
    ",map[3,i]= \\begin{bmatrix}\n",
    "3\\\\\n",
    "4\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "usando um pseudo código, utilizamos essa matriz mapeadora para montar a função global dada a local:\n",
    "<img src= \"./Figuras/pseudocodigo.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mapeamento \n",
    "Assim a matriz de massa *global* $M$ definida como $M_{ij} = \\int_\\Omega \\Phi_i\\ \\Phi_j \\partial x$ analogamente como  o código anterior, pode ser reescrita a função de uma matriz de massa $M^e$ *local*, utilizando uma matriz de mapeamento $map$ similar a anterior.\n",
    "<img src=\"./Figuras/Matrix_element.png\">\n",
    " Com o exemplo anterior conseguimos ter uma idéia de como remapear as respectivas matrizes para funções lineares, porém utilizando polinômios de maior grau podemos usar o mesmo código para essa reestruturação. Sendo assim podemos usar polinômios de Lagrange, Legendre ou mesmo uma nova base da família do polinômio de Jacobi para obter assim solucionar problemas mais complexos que não poderíamos solucionar com uma função linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Condensação estática\n",
    " Após o mapeamento das matrizes temos então a tarefa de resolver o sistema linear.Utilizando o fato do mapeamento ter separado as funções de base para os modos ***internos*** (i) e os modos de ***fronteira*** (b) de cada elemento, aplicamos a técnica de **condensação estática**. Onde com remapeando os vetores x e f do sistema linear $A\\  x = f$ de maneira a ficar primeiro os coeficientes de fronteira e depois os coeficientes internos temos o sistema reescrito como:\n",
    "  \\begin{equation}\n",
    "    x = \\left\\{\\begin{matrix} x_b \\\\ x_i \\\\ \\end{matrix}\\right\\}\\ ,\\ f =  \\left\\{\\begin{matrix} f_b \\\\ f_i \\\\ \\end{matrix}\\right\\}\\\n",
    "  \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Condensação estática\n",
    "E com o remapeamento feito anteriormente, temos a matriz A global como:\n",
    "\n",
    "<img src=\"./Figuras/Matriz_global.png\">\n",
    "onde cada $A_{\\cdot \\cdot}$ é uma sub matriz de A em que $A_{ii}$ é uma matriz em banda, $A_{ib}$ e $A_{bi}$ são  matrizes esparsas e $A_{bb}$ é uma matriz em bloco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Condensação estática\n",
    "\\begin{equation}\n",
    "A\\cdot x  = \\left[ \n",
    "\\begin{matrix} \n",
    "A_{bb} & A_{bi} \\\\\n",
    "A_{ib} & A_{ii} \\\\\n",
    "\\end{matrix}\\right] \\cdot \\left\\{\n",
    "\\begin{matrix} x_b \\\\ x_i \\\\ \n",
    "\\end{matrix}\\right\\} = \n",
    "\\left\\{\\begin{matrix} f_b \\\\ f_i \\\\\\end{matrix}\\right\\} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Condensação estática\n",
    "\n",
    "Para resolver esse sistemas fazemos:\n",
    "\\begin{equation}\n",
    "x_i = A_{ii}^{-1} f_i - A_{ii}^{-1} A_{ib} x_b\n",
    "\\end{equation}\n",
    "Que substituindo $x_i$ na equação de  $x_b$, obtemos:\n",
    "\\begin{equation}\n",
    "\\left( A_{bb} - A_{bi}A_{ii}^{-1} A_{ib} \\right) x_b = f_b - A_{bi}A_{ii}^{-1} f_i\\\\\n",
    "A'_{bb} \\cdot x_b = f'_b\n",
    "\\end{equation}\n",
    "onde:\n",
    "\\begin{align}\n",
    "& A'_{bb} = A_{bb} - A_{bi}A_{ii}^{-1} A_{ib}\\\\ \n",
    "& f'_b = f_b - A_{bi}A_{ii}^{-1} f_i\n",
    "\\end{align}\n",
    "Assim, utilizando o remapeamento e a condensação estática, encontramos $x_b$ e $x_i$ da equação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulação\n",
    "\n",
    "## Convergência do erro no fenômeno Runge\n",
    "Vamos agora ver a convergência do erro da aproximaçãode uma função de runge $\\frac{1}{1+x^2},\\ x\\ \\in [-5,5]$, para pontos **equidistantes** e pontos igualmente espaçados, utilizando o polinômio de **Lagrange**.\n",
    "<img src=\"./Figuras/interpolacao_todas.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulação\n",
    "## Convergência do erro no fenômeno Runge [método espectral]\n",
    "<img src=\"./Figuras/glj_equi.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulação\n",
    "## Convergência do erro no fenômeno Runge [método espectral]\n",
    "<img src=\"./Figuras/glj_cheb.png\" width=750>\n",
    "Notamos que embora a convergência, utilizando ambas as raízes dos polinômios, tenham o mesmo comportamento, podemos observar que como demonstrado  anteriormente a escolha do Polinômio de Chebyshev é o que melhor aproxima a função do fenômeno de Runge observando uma inclinação menor do erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergência do erro no fenômeno Runge [método HP]\n",
    "<img src=\"./Figuras/interp_usando_FEM.png\">\n",
    "<img src=\"./Figuras/interp_usando_FEMfixo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./Figuras/convergencia_erro_FEM2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Método HP na resolução de equações diferenciais\n",
    "## Condição de Dirichlet\n",
    " Agora, resolveremos uma equação diferencial de segundo grau. Para tanto, irei apresentar uma equação com solução conhecida ($sin(2\\ k \\pi x)$). Nesse caso, definirei o problema com a condição de fronteira de **Dirichlet**, definindo assim o valor nas extremidades do domínio.\n",
    " \\begin{align}\n",
    "y'' + y &= (1 + 4 (k \\pi)^2)sin(2 k \\pi x) \\\\\n",
    "y(-1) &= sin(-2\\ k \\ \\pi ) = 0 ,\\ y(1) = sin(2\\ k\\ \\pi) = 0 \\ \\ \\forall k = 1,2,\\dots \\\\\n",
    "\\end{align}\t\n",
    "<img src=\"./Figuras/solu_edo_simul.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergência do erro para Dirichlet\n",
    "<img src=\"./Figuras/convergencia_erro_HP.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Condição de Neumann\n",
    " Agora utilizamos o método HP para um problema no qual temos em uma das extremidades uma condição de ***Neumann***. Nesse exemplo usarei como solução do problema $y(x) = \\cos(10 x) \\sin(25 x)$, onde $ x \\in [-1,1]$ e a condição de Neuman está em $x=1$. Nesse caso temos que acrescentar o termo  $v_j(1) \\frac{\\partial y(1)}{\\partial x}$  ao lado direito da equação durante a solução da formulação fraca:\n",
    "\\begin{equation}\n",
    "\\\\-y'' + y = 726\\,\\cos \\left(10\\,x\\right)\\,\\sin \\left(25\\,x\\right)+500\\,\\sin \n",
    " \\left(10\\,x\\right)\\,\\cos \\left(25\\,x\\right) \n",
    "\\end{equation}\n",
    "<img src=\"./Figuras/Neumm_10_15.png\" width= 650>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A convergência dos erros utilizando o método P e o método H continuam semelhantes à convergência do erro dos métodos aplicado a condição de ***Dirichlet***:\n",
    "<img src=\"./Figuras/convergencia_erro_Neumm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Agora veremos a convergência do erro para a aproximada da \\emph{derivada} da solução no ponto onde temos a condição de ***Neumann*** ocorre:\n",
    " <img src=\"./Figuras/erro_derivada.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  },
  "livereveal": {
   "font-size": "50%",
   "theme": "serif",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
